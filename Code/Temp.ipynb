{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  9447\n",
      "Embedding Size:  100\n"
     ]
    }
   ],
   "source": [
    "# Load Pretrained Model\n",
    "path = '../Pretrained_Models/'\n",
    "w2v_model = Word2Vec.load('../Pretrained_Models/TREC_pretrain.model')\n",
    "\n",
    "pretrained_weights = w2v_model.wv.vectors\n",
    "vocab_size, embedding_size = pretrained_weights.shape\n",
    "\n",
    "print(\"Vocab Size: \", vocab_size)\n",
    "print(\"Embedding Size: \", embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size:  3861\n",
      "Development Size:  500\n",
      "Test Size:  1091\n"
     ]
    }
   ],
   "source": [
    "path = '../Datasets/Processed/TREC'\n",
    "\n",
    "training_dev_df = pd.read_csv(f'{path}/train.dev.csv')\n",
    "training_df = pd.read_csv(f'{path}/train.csv')\n",
    "test_df = pd.read_csv(f'{path}/test.csv')\n",
    "print(\"Training Size: \", training_df.shape[0])\n",
    "print(\"Development Size: \", training_dev_df.shape[0])\n",
    "print(\"Test Size: \", test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "training_df['label-coarse'] = label_encoder.fit_transform(training_df['label-coarse'])\n",
    "training_dev_df['label-coarse'] = label_encoder.fit_transform(training_dev_df['label-coarse'])\n",
    "test_df['label-coarse'] = label_encoder.fit_transform(test_df['label-coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "#tokenizer.fit_on_texts(training_dev_df['text'])\n",
    "tokenizer.fit_on_texts(training_df['text'])\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_sequences = tokenizer.texts_to_sequences(training_df['text'])\n",
    "X_val_sequences = tokenizer.texts_to_sequences(training_dev_df['text'])\n",
    "X_test_sequences = tokenizer.texts_to_sequences(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "sequence_length = 50  # Choose an appropriate sequence length\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=sequence_length, padding='post')\n",
    "X_val_padded = pad_sequences(X_val_sequences, maxlen=sequence_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=sequence_length, padding='post')\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "y_train = to_categorical(training_df['label-coarse'])\n",
    "y_val = to_categorical(training_dev_df['label-coarse'])\n",
    "y_test = to_categorical(test_df['label-coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=sequence_length))\n",
    "model.add(LSTM(units=100))  # You can adjust the number of LSTM units\n",
    "#model.add(LSTM(units=100, activation=\"relu\", kernel_regularizer=regularizers.L1L2(l1=0.001, l2=0.001)))  # You can adjust the number of LSTM units\n",
    "model.add(Dense(units=256, activation= \"relu\", kernel_regularizer=regularizers.L1L2(l1=0.0025, l2=0.0025)))\n",
    "model.add(Dropout(0.01))          \n",
    "#model.add(Dense(units=256, activation= \"relu\", kernel_regularizer=regularizers.L1L2(l1=0.0025, l2=0.0025)))\n",
    "#model.add(Dropout(0.01))\n",
    "#model.add(Dense(units=256, activation= \"relu\", kernel_regularizer=regularizers.L1L2(l1=0.0025, l2=0.0025)))\n",
    "#model.add(Dropout(0.01))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "39/39 [==============================] - 3s 45ms/step - loss: 4.7580 - accuracy: 0.4465 - val_loss: 3.7041 - val_accuracy: 0.4220\n",
      "Epoch 2/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 2.9768 - accuracy: 0.4530 - val_loss: 2.3670 - val_accuracy: 0.4220\n",
      "Epoch 3/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.9525 - accuracy: 0.4530 - val_loss: 1.6698 - val_accuracy: 0.4220\n",
      "Epoch 4/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.5204 - accuracy: 0.4530 - val_loss: 1.4726 - val_accuracy: 0.4220\n",
      "Epoch 5/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.4173 - accuracy: 0.4530 - val_loss: 1.4270 - val_accuracy: 0.4220\n",
      "Epoch 6/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3939 - accuracy: 0.4530 - val_loss: 1.4054 - val_accuracy: 0.4220\n",
      "Epoch 7/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3814 - accuracy: 0.4530 - val_loss: 1.4072 - val_accuracy: 0.4220\n",
      "Epoch 8/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3741 - accuracy: 0.4530 - val_loss: 1.4007 - val_accuracy: 0.4220\n",
      "Epoch 9/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3717 - accuracy: 0.4530 - val_loss: 1.3997 - val_accuracy: 0.4220\n",
      "Epoch 10/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3654 - accuracy: 0.4530 - val_loss: 1.3973 - val_accuracy: 0.4220\n",
      "Epoch 11/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3733 - accuracy: 0.4530 - val_loss: 1.4042 - val_accuracy: 0.4220\n",
      "Epoch 12/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3731 - accuracy: 0.4530 - val_loss: 1.3857 - val_accuracy: 0.4220\n",
      "Epoch 13/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3603 - accuracy: 0.4530 - val_loss: 1.3854 - val_accuracy: 0.4220\n",
      "Epoch 14/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3587 - accuracy: 0.4530 - val_loss: 1.3831 - val_accuracy: 0.4220\n",
      "Epoch 15/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3551 - accuracy: 0.4530 - val_loss: 1.3870 - val_accuracy: 0.4220\n",
      "Epoch 16/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3591 - accuracy: 0.4530 - val_loss: 1.3824 - val_accuracy: 0.4220\n",
      "Epoch 17/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3559 - accuracy: 0.4530 - val_loss: 1.3782 - val_accuracy: 0.4220\n",
      "Epoch 18/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3517 - accuracy: 0.4530 - val_loss: 1.3769 - val_accuracy: 0.4220\n",
      "Epoch 19/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3571 - accuracy: 0.4530 - val_loss: 1.3781 - val_accuracy: 0.4220\n",
      "Epoch 20/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3519 - accuracy: 0.4530 - val_loss: 1.3753 - val_accuracy: 0.4220\n",
      "Epoch 21/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3485 - accuracy: 0.4530 - val_loss: 1.3757 - val_accuracy: 0.4220\n",
      "Epoch 22/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3484 - accuracy: 0.4530 - val_loss: 1.3744 - val_accuracy: 0.4220\n",
      "Epoch 23/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3482 - accuracy: 0.4530 - val_loss: 1.3751 - val_accuracy: 0.4220\n",
      "Epoch 24/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3485 - accuracy: 0.4530 - val_loss: 1.3744 - val_accuracy: 0.4220\n",
      "Epoch 25/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3480 - accuracy: 0.4530 - val_loss: 1.3749 - val_accuracy: 0.4220\n",
      "Epoch 26/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3477 - accuracy: 0.4530 - val_loss: 1.3753 - val_accuracy: 0.4220\n",
      "Epoch 27/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3485 - accuracy: 0.4530 - val_loss: 1.3753 - val_accuracy: 0.4220\n",
      "Epoch 28/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3481 - accuracy: 0.4530 - val_loss: 1.3750 - val_accuracy: 0.4220\n",
      "Epoch 29/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3480 - accuracy: 0.4530 - val_loss: 1.3751 - val_accuracy: 0.4220\n",
      "Epoch 30/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3477 - accuracy: 0.4530 - val_loss: 1.3742 - val_accuracy: 0.4220\n",
      "Epoch 31/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3478 - accuracy: 0.4530 - val_loss: 1.3761 - val_accuracy: 0.4220\n",
      "Epoch 32/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3483 - accuracy: 0.4530 - val_loss: 1.3748 - val_accuracy: 0.4220\n",
      "Epoch 33/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3480 - accuracy: 0.4530 - val_loss: 1.3755 - val_accuracy: 0.4220\n",
      "Epoch 34/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3482 - accuracy: 0.4530 - val_loss: 1.3749 - val_accuracy: 0.4220\n",
      "Epoch 35/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3480 - accuracy: 0.4530 - val_loss: 1.3746 - val_accuracy: 0.4220\n",
      "Epoch 36/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3483 - accuracy: 0.4530 - val_loss: 1.3736 - val_accuracy: 0.4220\n",
      "Epoch 37/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3486 - accuracy: 0.4530 - val_loss: 1.3748 - val_accuracy: 0.4220\n",
      "Epoch 38/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3485 - accuracy: 0.4530 - val_loss: 1.3754 - val_accuracy: 0.4220\n",
      "Epoch 39/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3483 - accuracy: 0.4530 - val_loss: 1.3748 - val_accuracy: 0.4220\n",
      "Epoch 40/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3482 - accuracy: 0.4530 - val_loss: 1.3758 - val_accuracy: 0.4220\n",
      "Epoch 41/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3483 - accuracy: 0.4530 - val_loss: 1.3759 - val_accuracy: 0.4220\n",
      "Epoch 42/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3487 - accuracy: 0.4530 - val_loss: 1.3756 - val_accuracy: 0.4220\n",
      "Epoch 43/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3484 - accuracy: 0.4530 - val_loss: 1.3753 - val_accuracy: 0.4220\n",
      "Epoch 44/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3482 - accuracy: 0.4530 - val_loss: 1.3744 - val_accuracy: 0.4220\n",
      "Epoch 45/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3483 - accuracy: 0.4530 - val_loss: 1.3746 - val_accuracy: 0.4220\n",
      "Epoch 46/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3478 - accuracy: 0.4530 - val_loss: 1.3749 - val_accuracy: 0.4220\n",
      "Epoch 47/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3484 - accuracy: 0.4530 - val_loss: 1.3767 - val_accuracy: 0.4220\n",
      "Epoch 48/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3482 - accuracy: 0.4530 - val_loss: 1.3755 - val_accuracy: 0.4220\n",
      "Epoch 49/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3487 - accuracy: 0.4530 - val_loss: 1.3751 - val_accuracy: 0.4220\n",
      "Epoch 50/1000\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 1.3487 - accuracy: 0.4530 - val_loss: 1.3746 - val_accuracy: 0.4220\n",
      "Epoch 51/1000\n",
      "39/39 [==============================] - 1s 39ms/step - loss: 1.3482 - accuracy: 0.4530 - val_loss: 1.3748 - val_accuracy: 0.4220\n",
      "Epoch 52/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3484 - accuracy: 0.4530 - val_loss: 1.3751 - val_accuracy: 0.4220\n",
      "Epoch 53/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3484 - accuracy: 0.4530 - val_loss: 1.3749 - val_accuracy: 0.4220\n",
      "Epoch 54/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3490 - accuracy: 0.4530 - val_loss: 1.3753 - val_accuracy: 0.4220\n",
      "Epoch 55/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3484 - accuracy: 0.4530 - val_loss: 1.3749 - val_accuracy: 0.4220\n",
      "Epoch 56/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3488 - accuracy: 0.4530 - val_loss: 1.3749 - val_accuracy: 0.4220\n",
      "Epoch 57/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 1.3490 - accuracy: 0.4530 - val_loss: 1.3751 - val_accuracy: 0.4220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3487 - accuracy: 0.4530 - val_loss: 1.3771 - val_accuracy: 0.4220\n",
      "Epoch 59/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3489 - accuracy: 0.4530 - val_loss: 1.3746 - val_accuracy: 0.4220\n",
      "Epoch 60/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.3484 - accuracy: 0.4530 - val_loss: 1.3632 - val_accuracy: 0.4220\n",
      "Epoch 61/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 1.1725 - accuracy: 0.4595 - val_loss: 1.1583 - val_accuracy: 0.5020\n",
      "Epoch 62/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.9593 - accuracy: 0.6208 - val_loss: 1.0266 - val_accuracy: 0.5700\n",
      "Epoch 63/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.8277 - accuracy: 0.6496 - val_loss: 0.9844 - val_accuracy: 0.5740\n",
      "Epoch 64/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.7651 - accuracy: 0.6734 - val_loss: 0.9737 - val_accuracy: 0.6220\n",
      "Epoch 65/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.6535 - accuracy: 0.7682 - val_loss: 0.8370 - val_accuracy: 0.6920\n",
      "Epoch 66/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.5065 - accuracy: 0.8133 - val_loss: 0.8223 - val_accuracy: 0.7020\n",
      "Epoch 67/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.4666 - accuracy: 0.8205 - val_loss: 0.8156 - val_accuracy: 0.7180\n",
      "Epoch 68/1000\n",
      "39/39 [==============================] - 2s 41ms/step - loss: 0.4311 - accuracy: 0.8262 - val_loss: 0.8135 - val_accuracy: 0.7140\n",
      "Epoch 69/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.4099 - accuracy: 0.8280 - val_loss: 0.8157 - val_accuracy: 0.7120\n",
      "Epoch 70/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.3849 - accuracy: 0.8570 - val_loss: 0.7878 - val_accuracy: 0.7780\n",
      "Epoch 71/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.2877 - accuracy: 0.9422 - val_loss: 0.8937 - val_accuracy: 0.7980\n",
      "Epoch 72/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.2322 - accuracy: 0.9635 - val_loss: 0.9331 - val_accuracy: 0.7780\n",
      "Epoch 73/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.1940 - accuracy: 0.9769 - val_loss: 0.8327 - val_accuracy: 0.8180\n",
      "Epoch 74/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.1660 - accuracy: 0.9865 - val_loss: 0.8762 - val_accuracy: 0.7960\n",
      "Epoch 75/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.1540 - accuracy: 0.9860 - val_loss: 0.8448 - val_accuracy: 0.8120\n",
      "Epoch 76/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.1330 - accuracy: 0.9917 - val_loss: 0.8760 - val_accuracy: 0.8020\n",
      "Epoch 77/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.1290 - accuracy: 0.9904 - val_loss: 0.8652 - val_accuracy: 0.8140\n",
      "Epoch 78/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.1259 - accuracy: 0.9904 - val_loss: 0.9353 - val_accuracy: 0.8020\n",
      "Epoch 79/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.1176 - accuracy: 0.9920 - val_loss: 0.8053 - val_accuracy: 0.8280\n",
      "Epoch 80/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.1145 - accuracy: 0.9915 - val_loss: 0.8602 - val_accuracy: 0.8140\n",
      "Epoch 81/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.1128 - accuracy: 0.9925 - val_loss: 0.8553 - val_accuracy: 0.8140\n",
      "Epoch 82/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.1009 - accuracy: 0.9951 - val_loss: 0.8894 - val_accuracy: 0.8080\n",
      "Epoch 83/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.0940 - accuracy: 0.9959 - val_loss: 0.8519 - val_accuracy: 0.8040\n",
      "Epoch 84/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.0882 - accuracy: 0.9966 - val_loss: 0.8721 - val_accuracy: 0.8140\n",
      "Epoch 85/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.0892 - accuracy: 0.9964 - val_loss: 0.8485 - val_accuracy: 0.8180\n",
      "Epoch 86/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.0897 - accuracy: 0.9959 - val_loss: 0.8630 - val_accuracy: 0.8180\n",
      "Epoch 87/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.1047 - accuracy: 0.9907 - val_loss: 0.8912 - val_accuracy: 0.8220\n",
      "Epoch 88/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.1054 - accuracy: 0.9912 - val_loss: 0.9400 - val_accuracy: 0.7980\n",
      "Epoch 89/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.0927 - accuracy: 0.9938 - val_loss: 0.9147 - val_accuracy: 0.8120\n",
      "Epoch 90/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.0943 - accuracy: 0.9927 - val_loss: 0.8629 - val_accuracy: 0.8200\n",
      "Epoch 91/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.0826 - accuracy: 0.9951 - val_loss: 0.9311 - val_accuracy: 0.7840\n",
      "Epoch 92/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.0828 - accuracy: 0.9946 - val_loss: 0.9995 - val_accuracy: 0.7960\n",
      "Epoch 93/1000\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.0830 - accuracy: 0.9943 - val_loss: 0.8749 - val_accuracy: 0.8120\n",
      "Epoch 94/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.0758 - accuracy: 0.9961 - val_loss: 0.8886 - val_accuracy: 0.8100\n",
      "Epoch 95/1000\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.0722 - accuracy: 0.9961 - val_loss: 0.8608 - val_accuracy: 0.8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x209c34a14c0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "batch_size = 100\n",
    "\n",
    "model.fit(X_train_padded, y_train, epochs=num_epochs, batch_size=batch_size, shuffle=True, validation_data = (X_val_padded, y_val), \n",
    "          callbacks = early_stopping, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 4ms/step - loss: 0.8841 - accuracy: 0.8048\n",
      "Test Loss: 0.8840816020965576, Test Accuracy: 0.8047662973403931\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
